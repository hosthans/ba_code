{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from reinforcment_based.model.classifier import VGG16\n",
    "from reinforcment_based.model.evaluator import FaceNet\n",
    "from reinforcment_based.model.SAC import Agent\n",
    "from reinforcment_based.model.gan import Generator, Generator_MNIST\n",
    "from reinforcment_based.utils.mi_attack import inversion_dcgan, inversion_MNIST_DP\n",
    "from reinforcment_based.utils.file_utils import load_my_state_dict, low2high, seed_everything\n",
    "import pickle\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"VGG16\"\n",
    "MAX_EPISODES = 40000\n",
    "MAX_STEP = 1\n",
    "SEED = 42\n",
    "ALPHA = 0\n",
    "N_CLASSES = 10\n",
    "Z_DIM = 100\n",
    "N_TARGET = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load generator trained on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator_MNIST(\n",
       "    (l1): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=8192, bias=False)\n",
       "      (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (l2_5): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (3): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
       "      (4): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G = Generator(Z_DIM)\n",
    "# path_G = \"../training/data/model_data/gan/GeneratorMNISTDCGAN500EPOCHS.tar\"\n",
    "# G = torch.nn.DataParallel(G).cuda()\n",
    "# G.load_state_dict(torch.load(path_G)['state_dict'], strict=False)\n",
    "# G.eval()\n",
    "\n",
    "G = Generator_MNIST(100)\n",
    "path_G = \"checkpoints/gan/Generatormnist.tar\"\n",
    "G = torch.nn.DataParallel(G).cuda()\n",
    "G.load_state_dict(torch.load(path_G)['state_dict'], strict=False)\n",
    "G.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG16(\n",
       "    (feature): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace=True)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc_layer): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = VGG16(N_CLASSES)\n",
    "# path_T = \"../training/data/model_data/VGG16/VGG16MNIST.tar\"\n",
    "path_T = \"checkpoints/VGG16/dp_VGG16mnist.tar\"\n",
    "T = torch.nn.DataParallel(T).cuda()\n",
    "T.load_state_dict(torch.load(path_T)['state_dict'], strict=False)\n",
    "T.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evaluator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG16(\n",
       "    (feature): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace=True)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace=True)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc_layer): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = VGG16(N_CLASSES)\n",
    "path_E = 'checkpoints/VGG16/dp_VGG16mnist.tar'\n",
    "E = torch.nn.DataParallel(E).cuda()\n",
    "E.load_state_dict(torch.load(path_E)['state_dict'], strict=False)\n",
    "E.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "cnt = 0\n",
    "cnt5 = 0\n",
    "\n",
    "identities = range(N_CLASSES)\n",
    "targets = random.sample(identities, N_TARGET)\n",
    "os.makedirs(\"attack_results/reinforcment_mnist_dp/images\", exist_ok=True)\n",
    "os.makedirs(\"attack_results/reinforcment_mnist_dp/models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Label : 1\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.0951\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.0952\n",
      "Episodes 30000/40000, Confidence score for the target model : 0.0952\n",
      "Episodes 40000/40000, Confidence score for the target model : 0.0954\n",
      "Classes 1/10, Accuracy : 0.000, Top-5 Accuracy : 1.000\n",
      "duration for 40000 episodes: 716.85\n",
      "Target Label : 0\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.1021\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.1021\n",
      "Episodes 30000/40000, Confidence score for the target model : 0.1022\n",
      "Episodes 40000/40000, Confidence score for the target model : 0.1022\n",
      "Classes 2/10, Accuracy : 0.000, Top-5 Accuracy : 0.500\n",
      "duration for 40000 episodes: 708.47\n",
      "Target Label : 4\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.0942\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.0942\n",
      "Episodes 30000/40000, Confidence score for the target model : 0.0942\n",
      "Episodes 40000/40000, Confidence score for the target model : 0.0944\n",
      "Classes 3/10, Accuracy : 0.000, Top-5 Accuracy : 0.667\n",
      "duration for 40000 episodes: 689.03\n",
      "Target Label : 9\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.1129\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.1137\n",
      "Episodes 30000/40000, Confidence score for the target model : 0.1141\n",
      "Episodes 40000/40000, Confidence score for the target model : 0.1144\n",
      "Classes 4/10, Accuracy : 0.000, Top-5 Accuracy : 0.750\n",
      "duration for 40000 episodes: 651.69\n",
      "Target Label : 6\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.1017\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.1019\n",
      "Episodes 30000/40000, Confidence score for the target model : 0.1019\n",
      "Episodes 40000/40000, Confidence score for the target model : 0.1020\n",
      "Classes 5/10, Accuracy : 0.000, Top-5 Accuracy : 0.800\n",
      "duration for 40000 episodes: 653.24\n",
      "Target Label : 5\n",
      "Episodes 10000/40000, Confidence score for the target model : 0.1037\n",
      "Episodes 20000/40000, Confidence score for the target model : 0.1037\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(state_size\u001b[38;5;241m=\u001b[39mZ_DIM, action_size\u001b[38;5;241m=\u001b[39mZ_DIM, random_seed\u001b[38;5;241m=\u001b[39mSEED, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, action_prior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m recon_image \u001b[38;5;241m=\u001b[39m \u001b[43minversion_MNIST_DP\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mALPHA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_STEP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m output\u001b[38;5;241m=\u001b[39m E(recon_image)\n\u001b[1;32m      6\u001b[0m eval_prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output[\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/reinforcment_based/utils/mi_attack.py:163\u001b[0m, in \u001b[0;36minversion_MNIST_DP\u001b[0;34m(agent, G, T, alpha, z_dim, max_episodes, max_step, label, model_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m state \u001b[38;5;241m=\u001b[39m deepcopy(z\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_step):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# print(state.shape)\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# Update the state and create images from the updated state and action.\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     z \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m z \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m action\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(action)))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    165\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m deepcopy(z\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/reinforcment_based/model/SAC.py:183\u001b[0m, in \u001b[0;36mAgent.act\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns actions for given state as per current policy.\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(state)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 183\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/reinforcment_based/model/SAC.py:88\u001b[0m, in \u001b[0;36mActor.get_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     86\u001b[0m dist \u001b[38;5;241m=\u001b[39m Normal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m e      \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 88\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#action = torch.clamp(action*action_high, action_low, action_high)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in targets:\n",
    "        start = time.time()\n",
    "        agent = Agent(state_size=Z_DIM, action_size=Z_DIM, random_seed=SEED, hidden_size=256, action_prior=\"uniform\")\n",
    "        recon_image = inversion_MNIST_DP(agent, G, T, ALPHA, z_dim=Z_DIM, max_episodes=MAX_EPISODES, max_step=MAX_STEP, label=i, model_name=MODEL_NAME)\n",
    "        output= E(recon_image)\n",
    "        eval_prob = F.softmax(output[1], dim=1)\n",
    "        top_idx = torch.argmax(eval_prob)\n",
    "        _, top5_idx = torch.topk(eval_prob, 5)\n",
    "\n",
    "        total += 1\n",
    "        if top_idx == i:\n",
    "            cnt += 1\n",
    "        if i in top5_idx:\n",
    "            cnt5 += 1\n",
    "\n",
    "        # prop = T(recon_image)\n",
    "        # print(prop)\n",
    "\n",
    "        acc = cnt / total\n",
    "        acc5 = cnt5 / total\n",
    "        print(\"Classes {}/{}, Accuracy : {:.3f}, Top-5 Accuracy : {:.3f}\".format(total, N_TARGET, acc, acc5))\n",
    "        end = time.time()\n",
    "        total_time = end-start\n",
    "        print(f\"duration for {MAX_EPISODES} episodes: {total_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
