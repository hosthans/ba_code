{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedmi.models.generator import *\n",
    "from kedmi.models.discri import *\n",
    "from kedmi.utils.helper import *\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from kedmi.utils.kedmi_attack import mnist_inversion, dist_inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specified configuration and specify environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/kedmi/config/celeba/attacking/mnist_cust.json\"\n",
    "configuration = load_json(json_file=CONFIG_PATH)\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    f\"{configuration['dataset']['name']}_{configuration['dataset']['model_name']}\",\n",
    "    configuration[\"attack\"][\"variant\"],\n",
    ")\n",
    "prefix = os.path.join(\n",
    "    os.path.join(configuration[\"root_path\"], \"kedmi_300ids\"), save_folder\n",
    ")\n",
    "save_dir = os.path.join(prefix, \"latent\")\n",
    "save_img_dir = os.path.join(\n",
    "    prefix, \"imgs_{}\".format(configuration[\"attack\"][\"variant\"])\n",
    ")\n",
    "\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(configuration[\"dataset\"][\"p_reg_path\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VGG16', 'VGG16']\n",
      "Load MNIST_GAN\n",
      "path_G checkpoints/gan/Generatormnist.tar\n",
      "path_D checkpoints/gan/Discriminatormnist.tar\n",
      "0\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/VGG16/nn_VGG16mnist.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/VGG16/nn_VGG16mnist.tar\n"
     ]
    }
   ],
   "source": [
    "targetnets, E, G, D, n_classes, fea_mean, fea_logvar = get_attack_model(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set necessary params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): DGWGAN_MNIST(\n",
      "    (ls): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "bs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Attack batch [0]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torch/nn/parallel/comm.py:227: UserWarning: Using -1 to represent CPU tensor is deprecated. Please use a device object or string instead, e.g., \"cpu\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.60\tIden Loss:-15.42\tAttack Acc:93.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:600\tPrior Loss:23.96\tIden Loss:-17.87\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:900\tPrior Loss:23.91\tIden Loss:-18.51\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.33\tIden Loss:-19.17\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.47\tIden Loss:-19.66\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.17\tIden Loss:-20.20\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2100\tPrior Loss:22.97\tIden Loss:-20.56\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.47\tIden Loss:-21.13\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2700\tPrior Loss:22.48\tIden Loss:-21.52\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3000\tPrior Loss:22.69\tIden Loss:-22.02\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3300\tPrior Loss:22.42\tIden Loss:-22.29\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3600\tPrior Loss:22.57\tIden Loss:-22.67\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3900\tPrior Loss:22.76\tIden Loss:-22.78\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4200\tPrior Loss:22.65\tIden Loss:-22.94\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4500\tPrior Loss:22.67\tIden Loss:-23.04\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4800\tPrior Loss:22.67\tIden Loss:-23.10\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5100\tPrior Loss:22.60\tIden Loss:-23.13\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5400\tPrior Loss:22.61\tIden Loss:-23.18\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5700\tPrior Loss:22.60\tIden Loss:-23.20\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:6000\tPrior Loss:22.60\tIden Loss:-23.21\tAttack Acc:100.00\n",
      "--------------------- Attack batch [1]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.57\tIden Loss:-16.27\tAttack Acc:98.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:600\tPrior Loss:24.03\tIden Loss:-17.64\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:900\tPrior Loss:24.02\tIden Loss:-18.70\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.92\tIden Loss:-19.41\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.57\tIden Loss:-19.72\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.27\tIden Loss:-20.03\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2100\tPrior Loss:22.98\tIden Loss:-20.81\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.71\tIden Loss:-21.24\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2700\tPrior Loss:22.76\tIden Loss:-21.65\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3000\tPrior Loss:22.79\tIden Loss:-21.94\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3300\tPrior Loss:22.66\tIden Loss:-22.33\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3600\tPrior Loss:22.78\tIden Loss:-22.67\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3900\tPrior Loss:22.74\tIden Loss:-22.90\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4200\tPrior Loss:22.91\tIden Loss:-23.05\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4500\tPrior Loss:22.95\tIden Loss:-23.15\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4800\tPrior Loss:22.82\tIden Loss:-23.20\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5100\tPrior Loss:22.82\tIden Loss:-23.26\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5400\tPrior Loss:22.87\tIden Loss:-23.27\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5700\tPrior Loss:22.84\tIden Loss:-23.30\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:6000\tPrior Loss:22.82\tIden Loss:-23.32\tAttack Acc:100.00\n",
      "--------------------- Attack batch [2]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:300\tPrior Loss:23.78\tIden Loss:-16.44\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:600\tPrior Loss:23.74\tIden Loss:-17.18\tAttack Acc:96.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:900\tPrior Loss:24.29\tIden Loss:-18.64\tAttack Acc:98.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.42\tIden Loss:-19.47\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.06\tIden Loss:-19.67\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.19\tIden Loss:-19.99\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2100\tPrior Loss:23.04\tIden Loss:-20.83\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.84\tIden Loss:-20.96\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2700\tPrior Loss:22.58\tIden Loss:-21.55\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3000\tPrior Loss:22.97\tIden Loss:-21.87\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3300\tPrior Loss:22.78\tIden Loss:-22.23\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3600\tPrior Loss:22.85\tIden Loss:-22.61\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:3900\tPrior Loss:22.74\tIden Loss:-22.83\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4200\tPrior Loss:22.87\tIden Loss:-22.96\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4500\tPrior Loss:22.85\tIden Loss:-23.04\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:4800\tPrior Loss:22.82\tIden Loss:-23.13\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5100\tPrior Loss:22.85\tIden Loss:-23.16\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5400\tPrior Loss:22.86\tIden Loss:-23.19\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:5700\tPrior Loss:22.83\tIden Loss:-23.21\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:6000\tPrior Loss:22.86\tIden Loss:-23.23\tAttack Acc:100.00\n",
      "--------------------- Attack batch [3]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.05\tIden Loss:-16.35\tAttack Acc:96.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:600\tPrior Loss:24.28\tIden Loss:-17.81\tAttack Acc:98.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:900\tPrior Loss:24.00\tIden Loss:-18.53\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.85\tIden Loss:-19.26\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.40\tIden Loss:-19.93\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:1800\tPrior Loss:22.90\tIden Loss:-20.37\tAttack Acc:100.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "Iteration:2100\tPrior Loss:22.69\tIden Loss:-20.75\tAttack Acc:100.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m save_dir_z \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(save_dir, i, idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkedmi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m mnist_inversion(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     G,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     D,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     targetnets,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     E,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     iden,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     iter_times\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39miters_mi\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     momentum\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     lamda\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     clip_range\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     improved\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimproved_flag\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     num_seeds\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mnum_seeds\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     used_loss\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     prefix\u001b[39m=\u001b[39;49msave_dir_z,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     save_img_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_img_dir, \u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(idx)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     fea_mean\u001b[39m=\u001b[39;49mfea_mean,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     fea_logvar\u001b[39m=\u001b[39;49mfea_logvar,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     lam\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlam\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     clipz\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mclipz\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m iden \u001b[39m=\u001b[39m iden \u001b[39m+\u001b[39m bs\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/kedmi/utils/kedmi_attack.py:260\u001b[0m, in \u001b[0;36mmnist_inversion\u001b[0;34m(G, D, T, E, iden, lr, momentum, lamda, iter_times, clip_range, improved, num_seeds, used_loss, prefix, random_seed, save_img_dir, fea_mean, fea_logvar, lam, clipz)\u001b[0m\n\u001b[1;32m    256\u001b[0m Prior_Loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m label\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    258\u001b[0m Total_Loss \u001b[39m=\u001b[39m Prior_Loss \u001b[39m+\u001b[39m lamda \u001b[39m*\u001b[39m Iden_Loss\n\u001b[0;32m--> 260\u001b[0m Total_Loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    261\u001b[0m solver\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    263\u001b[0m Prior_Loss_val \u001b[39m=\u001b[39m Prior_Loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin attacking\n",
    "for i in range(1):\n",
    "    iden = torch.from_numpy(np.arange(bs))\n",
    "\n",
    "    # evaluate on the first 300 identities only\n",
    "    target_cosines = 0\n",
    "    eval_cosines = 0\n",
    "    for idx in range(5):\n",
    "        iden = iden % n_classes\n",
    "        print(\n",
    "            \"--------------------- Attack batch [%s]------------------------------\"\n",
    "            % idx\n",
    "        )\n",
    "        print(\"Iden:{}\".format(iden))\n",
    "        save_dir_z = \"{}/{}_{}\".format(save_dir, i, idx)\n",
    "        print(\"kedmi\")\n",
    "\n",
    "        mnist_inversion(\n",
    "            G,\n",
    "            D,\n",
    "            targetnets,\n",
    "            E,\n",
    "            iden,\n",
    "            lr=configuration[\"attack\"][\"lr\"],\n",
    "            iter_times=configuration[\"attack\"][\"iters_mi\"],\n",
    "            momentum=0.9,\n",
    "            lamda=100,\n",
    "            clip_range=1,\n",
    "            improved=configuration['attack']['improved_flag'],\n",
    "            num_seeds=configuration['attack']['num_seeds'],\n",
    "            used_loss=configuration['attack']['loss'],\n",
    "            prefix=save_dir_z,\n",
    "            save_img_dir=os.path.join(save_img_dir, \"{}_\".format(idx)),\n",
    "            fea_mean=fea_mean,\n",
    "            fea_logvar=fea_logvar,\n",
    "            lam=configuration[\"attack\"][\"lam\"],\n",
    "            clipz=configuration['attack']['clipz'],\n",
    "        )\n",
    "        iden = iden + bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
