{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedmi.models.generator import *\n",
    "from kedmi.models.discri import *\n",
    "from kedmi.utils.helper import *\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from kedmi.utils.kedmi_attack import mnist_inversion, dist_inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specified configuration and specify environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/kedmi/config/celeba/attacking/mnist_cust.json\"\n",
    "configuration = load_json(json_file=CONFIG_PATH)\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    f\"{configuration['dataset']['name']}_{configuration['dataset']['model_name']}\",\n",
    "    configuration[\"attack\"][\"variant\"],\n",
    ")\n",
    "prefix = os.path.join(\n",
    "    os.path.join(configuration[\"root_path\"], \"kedmi_300ids\"), save_folder\n",
    ")\n",
    "save_dir = os.path.join(prefix, \"latent\")\n",
    "save_img_dir = os.path.join(\n",
    "    prefix, \"imgs_{}\".format(configuration[\"attack\"][\"variant\"])\n",
    ")\n",
    "\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(configuration[\"dataset\"][\"p_reg_path\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VGG16', 'VGG16']\n",
      "Load MNIST_GAN\n",
      "path_G checkpoints/gan/Generatormnist.tar\n",
      "path_D checkpoints/gan/Discriminatormnist.tar\n",
      "0\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/VGG16/nn_VGG16mnist.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/VGG16/nn_VGG16mnist.tar\n"
     ]
    }
   ],
   "source": [
    "targetnets, E, G, D, n_classes, fea_mean, fea_logvar = get_attack_model(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set necessary params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): DGWGAN_MNIST(\n",
      "    (ls): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "      (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "bs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Attack batch [0]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torch/nn/parallel/comm.py:227: UserWarning: Using -1 to represent CPU tensor is deprecated. Please use a device object or string instead, e.g., \"cpu\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.20\tIden Loss:-16.74\tAttack Acc:41.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:600\tPrior Loss:24.38\tIden Loss:-17.89\tAttack Acc:48.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:900\tPrior Loss:23.59\tIden Loss:-19.23\tAttack Acc:53.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.54\tIden Loss:-19.51\tAttack Acc:55.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.19\tIden Loss:-20.19\tAttack Acc:48.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1800\tPrior Loss:22.92\tIden Loss:-20.97\tAttack Acc:55.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2100\tPrior Loss:22.66\tIden Loss:-21.28\tAttack Acc:51.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.23\tIden Loss:-21.74\tAttack Acc:53.33\n",
      "--------------------- Attack batch [1]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.92\tIden Loss:-16.83\tAttack Acc:45.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:600\tPrior Loss:23.75\tIden Loss:-18.23\tAttack Acc:48.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:900\tPrior Loss:23.41\tIden Loss:-18.89\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.56\tIden Loss:-19.69\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.45\tIden Loss:-20.24\tAttack Acc:51.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.34\tIden Loss:-20.58\tAttack Acc:51.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2100\tPrior Loss:22.94\tIden Loss:-21.33\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.74\tIden Loss:-21.76\tAttack Acc:48.33\n",
      "--------------------- Attack batch [2]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.12\tIden Loss:-16.17\tAttack Acc:41.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:600\tPrior Loss:24.01\tIden Loss:-18.18\tAttack Acc:46.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:900\tPrior Loss:23.90\tIden Loss:-19.14\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.69\tIden Loss:-19.75\tAttack Acc:51.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.48\tIden Loss:-20.51\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.12\tIden Loss:-21.00\tAttack Acc:55.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2100\tPrior Loss:23.09\tIden Loss:-21.11\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:2400\tPrior Loss:22.78\tIden Loss:-21.82\tAttack Acc:56.67\n",
      "--------------------- Attack batch [3]------------------------------\n",
      "Iden:tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:300\tPrior Loss:24.69\tIden Loss:-16.35\tAttack Acc:46.67\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:600\tPrior Loss:23.99\tIden Loss:-18.19\tAttack Acc:45.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:900\tPrior Loss:23.57\tIden Loss:-19.06\tAttack Acc:58.33\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1200\tPrior Loss:23.50\tIden Loss:-19.96\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1500\tPrior Loss:23.06\tIden Loss:-20.55\tAttack Acc:50.00\n",
      "torch.Size([60, 1, 64, 64])\n",
      "torch.Size([60, 3, 64, 64])\n",
      "Iteration:1800\tPrior Loss:23.01\tIden Loss:-21.01\tAttack Acc:51.67\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m save_dir_z \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(save_dir, i, idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkedmi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m mnist_inversion(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     G,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     D,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     targetnets,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     E,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     iden,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     iter_times\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39miters_mi\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     momentum\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     lamda\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     clip_range\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     improved\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimproved_flag\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     num_seeds\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mnum_seeds\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     used_loss\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     prefix\u001b[39m=\u001b[39;49msave_dir_z,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     save_img_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_img_dir, \u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(idx)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     fea_mean\u001b[39m=\u001b[39;49mfea_mean,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     fea_logvar\u001b[39m=\u001b[39;49mfea_logvar,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     lam\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlam\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     clipz\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mclipz\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_MNIST.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m iden \u001b[39m=\u001b[39m iden \u001b[39m+\u001b[39m bs\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/kedmi/utils/kedmi_attack.py:239\u001b[0m, in \u001b[0;36mmnist_inversion\u001b[0;34m(G, D, T, E, iden, lr, momentum, lamda, iter_times, clip_range, improved, num_seeds, used_loss, prefix, random_seed, save_img_dir, fea_mean, fea_logvar, lam, clipz)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m clipz\u001b[39m==\u001b[39m\u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     z \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mclamp(z,\u001b[39m-\u001b[39mclip_range,clip_range)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 239\u001b[0m fake \u001b[39m=\u001b[39m G(z)\n\u001b[1;32m    240\u001b[0m \u001b[39m# if fake.shape != torch.Size([64,3,64,64]):\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m# fake = torch.cat([fake]*3, dim=1)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m label \u001b[39m=\u001b[39m D(fake)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:175\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj:\n\u001b[1;32m    171\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule must have its parameters and buffers \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m                            \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon device \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj\u001b[39m}\u001b[39;00m\u001b[39m (device_ids[0]) but found one of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m                            \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthem on device: \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m inputs, module_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscatter(inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids)\n\u001b[1;32m    176\u001b[0m \u001b[39m# for forward function without any inputs, empty list and dict will be created\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# so the module can be executed on one device which is the first one in device_ids\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inputs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m module_kwargs:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:197\u001b[0m, in \u001b[0;36mDataParallel.scatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    193\u001b[0m     inputs: Tuple[Any, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m],\n\u001b[1;32m    194\u001b[0m     kwargs: Optional[Dict[\u001b[39mstr\u001b[39m, Any]],\n\u001b[1;32m    195\u001b[0m     device_ids: Sequence[Union[\u001b[39mint\u001b[39m, torch\u001b[39m.\u001b[39mdevice]],\n\u001b[1;32m    196\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_kwargs(inputs, kwargs, device_ids, dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:73\u001b[0m, in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_kwargs\u001b[39m(\n\u001b[1;32m     67\u001b[0m     inputs: Tuple[Any, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m],\n\u001b[1;32m     68\u001b[0m     kwargs: Optional[Dict[\u001b[39mstr\u001b[39m, Any]],\n\u001b[1;32m     69\u001b[0m     target_gpus: Sequence[Union[\u001b[39mint\u001b[39m, torch\u001b[39m.\u001b[39mdevice]],\n\u001b[1;32m     70\u001b[0m     dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m     71\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tuple[Any, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], Tuple[Dict[\u001b[39mstr\u001b[39m, Any], \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]:\n\u001b[1;32m     72\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     scattered_inputs \u001b[39m=\u001b[39m scatter(inputs, target_gpus, dim) \u001b[39mif\u001b[39;00m inputs \u001b[39melse\u001b[39;00m []\n\u001b[1;32m     74\u001b[0m     scattered_kwargs \u001b[39m=\u001b[39m scatter(kwargs, target_gpus, dim) \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m []\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scattered_inputs) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(scattered_kwargs):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:60\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# After scatter_map is called, a scatter_map cell will exist. This cell\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# has a reference to the actual function scatter_map, which has references\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# to a closure that has a reference to the scatter_map cell (because the\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# fn is recursive). To avoid this reference cycle, we set the function to\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# None, clearing the cell\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     res \u001b[39m=\u001b[39m scatter_map(inputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     scatter_map \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:47\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mtype\u001b[39m(obj)(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(scatter_map, obj)))\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mlist\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py:43\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_map\u001b[39m(obj):\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m---> 43\u001b[0m         \u001b[39mreturn\u001b[39;00m Scatter\u001b[39m.\u001b[39;49mapply(target_gpus, \u001b[39mNone\u001b[39;49;00m, dim, obj)\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m _is_namedtuple(obj):\n\u001b[1;32m     45\u001b[0m         \u001b[39mreturn\u001b[39;00m [\u001b[39mtype\u001b[39m(obj)(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:96\u001b[0m, in \u001b[0;36mScatter.forward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39mand\u001b[39;00m ctx\u001b[39m.\u001b[39minput_device \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[39m# Perform CPU to GPU copies in a background stream\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     streams \u001b[39m=\u001b[39m [_get_stream(torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, device)) \u001b[39mfor\u001b[39;00m device \u001b[39min\u001b[39;00m target_gpus]\n\u001b[0;32m---> 96\u001b[0m outputs \u001b[39m=\u001b[39m comm\u001b[39m.\u001b[39;49mscatter(\u001b[39minput\u001b[39;49m, target_gpus, chunk_sizes, ctx\u001b[39m.\u001b[39;49mdim, streams)\n\u001b[1;32m     97\u001b[0m \u001b[39m# Synchronize with the copy stream\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m streams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/comm.py:187\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     devices \u001b[39m=\u001b[39m [_get_device_index(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m devices]\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_scatter(tensor, devices, chunk_sizes, dim, streams))\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[39mif\u001b[39;00m devices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin attacking\n",
    "for i in range(1):\n",
    "    iden = torch.from_numpy(np.arange(bs))\n",
    "\n",
    "    # evaluate on the first 300 identities only\n",
    "    target_cosines = 0\n",
    "    eval_cosines = 0\n",
    "    for idx in range(5):\n",
    "        iden = iden % n_classes\n",
    "        print(\n",
    "            \"--------------------- Attack batch [%s]------------------------------\"\n",
    "            % idx\n",
    "        )\n",
    "        print(\"Iden:{}\".format(iden))\n",
    "        save_dir_z = \"{}/{}_{}\".format(save_dir, i, idx)\n",
    "        print(\"kedmi\")\n",
    "\n",
    "        mnist_inversion(\n",
    "            G,\n",
    "            D,\n",
    "            targetnets,\n",
    "            E,\n",
    "            iden,\n",
    "            lr=configuration[\"attack\"][\"lr\"],\n",
    "            iter_times=configuration[\"attack\"][\"iters_mi\"],\n",
    "            momentum=0.9,\n",
    "            lamda=100,\n",
    "            clip_range=1,\n",
    "            improved=configuration['attack']['improved_flag'],\n",
    "            num_seeds=configuration['attack']['num_seeds'],\n",
    "            used_loss=configuration['attack']['loss'],\n",
    "            prefix=save_dir_z,\n",
    "            save_img_dir=os.path.join(save_img_dir, \"{}_\".format(idx)),\n",
    "            fea_mean=fea_mean,\n",
    "            fea_logvar=fea_logvar,\n",
    "            lam=configuration[\"attack\"][\"lam\"],\n",
    "            clipz=configuration['attack']['clipz'],\n",
    "        )\n",
    "        iden = iden + bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
