{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedmi.models.generator import *\n",
    "from kedmi.models.discri import *\n",
    "from kedmi.utils.helper import *\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from kedmi.utils.kedmi_attack import mnist_inversion, dist_inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specified configuration and specify environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/kedmi/config/celeba/attacking/celeba_cust.json\"\n",
    "configuration = load_json(json_file=CONFIG_PATH)\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    f\"{configuration['dataset']['name']}_{configuration['dataset']['model_name']}\",\n",
    "    configuration[\"attack\"][\"variant\"],\n",
    ")\n",
    "prefix = os.path.join(\n",
    "    os.path.join(configuration[\"root_path\"], \"kedmi_300ids\"), save_folder\n",
    ")\n",
    "save_dir = os.path.join(prefix, \"latent\")\n",
    "save_img_dir = os.path.join(\n",
    "    prefix, \"imgs_{}\".format(configuration[\"attack\"][\"variant\"])\n",
    ")\n",
    "\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(configuration[\"dataset\"][\"p_reg_path\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VGG16', 'VGG16']\n",
      "path_G checkpoints/kedmi/GAN/celeba/VGG16/improved_celeba_G.tar\n",
      "path_D checkpoints/kedmi/GAN/celeba/VGG16/improved_celeba_D.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/coding/bachelorarbeit/ba_code/kedmi/models/discri.py:79: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.T, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/kedmi/target_ckp/VGG16.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bot/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "VGG16\n",
      "Load classifier VGG16 at checkpoints/kedmi/target_ckp/VGG16.tar\n"
     ]
    }
   ],
   "source": [
    "targetnets, E, G, D, n_classes, fea_mean, fea_logvar = get_attack_model(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set necessary params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "bs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Attack batch [0]------------------------------\n",
      "Iden:tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "tensor([[-14.5335, -15.7290, -13.0612,  ..., -16.5516, -15.0461, -14.8810],\n",
      "        [-16.3560, -21.6245, -20.8313,  ..., -16.6473, -15.1798, -18.8965],\n",
      "        [-15.7243, -16.7756, -12.4205,  ..., -12.9625, -12.0908, -16.9630],\n",
      "        ...,\n",
      "        [-16.4053, -16.7750, -20.2339,  ..., -15.8415, -14.6272, -15.8185],\n",
      "        [-12.4188, -17.9976, -16.7324,  ..., -17.6314, -19.1476, -18.1799],\n",
      "        [-11.0815, -17.2083, -21.5655,  ..., -15.8791, -17.7278, -15.2674]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-15.5337, -13.7604, -15.0633,  ..., -19.0237, -18.3799, -16.3100],\n",
      "        [-16.3413, -17.6570, -16.5524,  ..., -18.4349, -15.3196, -16.5927],\n",
      "        [-14.8024, -15.1242, -18.8702,  ..., -17.5333, -18.4153, -16.6914],\n",
      "        ...,\n",
      "        [-16.0667, -16.6106, -18.0724,  ...,  -9.3258,  -4.0368, -11.2867],\n",
      "        [-22.0871, -22.1480, -18.8548,  ..., -15.0030, -15.4263, -16.5997],\n",
      "        [-12.1472, -13.2298, -12.0490,  ..., -15.1021, -13.5085, -11.9556]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torch/nn/parallel/comm.py:227: UserWarning: Using -1 to represent CPU tensor is deprecated. Please use a device object or string instead, e.g., \"cpu\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-12.5372, -18.8626, -16.3484,  ..., -16.7543, -18.7840, -18.7207],\n",
      "        [-15.2312, -13.2150, -18.5398,  ..., -15.9043, -13.3358, -14.8370],\n",
      "        [-16.2851, -20.4362, -20.2565,  ..., -13.1798, -17.8322, -15.9593],\n",
      "        ...,\n",
      "        [-17.5826, -17.1679, -18.2639,  ..., -22.3893, -19.0860, -18.6612],\n",
      "        [-16.6056, -16.5862, -18.4062,  ..., -14.1063, -12.4852, -11.6360],\n",
      "        [-17.3960, -16.8748, -17.8101,  ..., -15.6079, -15.2336, -14.2277]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-16.0494, -16.8391, -19.5120,  ..., -18.9522, -15.3610, -16.4739],\n",
      "        [ -9.6460, -11.1410, -14.0723,  ..., -15.6311, -14.0035, -12.4323],\n",
      "        [-19.5309, -14.1626, -18.0175,  ..., -20.1880, -19.3038, -16.9919],\n",
      "        ...,\n",
      "        [-13.5220, -18.0244, -19.1770,  ..., -15.7211, -14.4183, -14.7680],\n",
      "        [-15.3647, -14.4510, -15.1202,  ..., -14.7086, -10.9742, -12.9048],\n",
      "        [-15.9811, -14.1694, -16.8809,  ..., -11.9795, -15.3191, -14.5799]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-17.3769, -20.2076, -20.3700,  ..., -18.6455, -16.7796, -14.4830],\n",
      "        [-13.5106, -12.4802, -14.6636,  ..., -15.2958, -14.8758, -13.8921],\n",
      "        [-13.1352, -18.9344, -21.6287,  ..., -17.2806, -14.9869, -20.7948],\n",
      "        ...,\n",
      "        [-13.9260, -17.3995, -20.6512,  ..., -18.0567, -12.8755, -14.1652],\n",
      "        [-12.7445, -13.4234, -14.9163,  ..., -10.7926, -10.6568, -11.7123],\n",
      "        [-12.0601, -16.3909, -15.6770,  ..., -15.5728, -17.5061, -14.7688]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-16.2109, -15.3453, -18.1630,  ..., -10.3761, -14.7650, -12.0174],\n",
      "        [-18.6604, -20.8535, -20.1926,  ..., -15.0364, -18.0680, -16.8522],\n",
      "        [-13.9567, -17.0765, -19.9798,  ..., -11.8755, -14.3914, -11.0635],\n",
      "        ...,\n",
      "        [-20.6880, -18.7672, -20.8797,  ..., -16.4822, -13.4394, -13.5805],\n",
      "        [-19.8537, -20.9337, -21.0040,  ..., -18.9735, -17.6614, -16.9148],\n",
      "        [ -9.4388, -10.3437, -17.4394,  ..., -14.3592, -15.0262, -11.9442]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-16.7558, -17.3902, -16.8750,  ..., -21.8339, -16.8080, -19.8323],\n",
      "        [-13.9676, -12.1170, -18.1358,  ..., -18.2682, -16.0325, -18.7459],\n",
      "        [-13.0887, -12.0153, -12.9510,  ..., -11.0679,  -9.6864,  -7.8191],\n",
      "        ...,\n",
      "        [-12.7830, -15.2675, -13.7421,  ..., -17.4450, -14.6027, -13.9555],\n",
      "        [-16.2999, -13.4328, -15.3125,  ..., -18.0677, -17.2577, -17.1537],\n",
      "        [-14.1421, -17.9106, -23.2242,  ..., -13.3692, -15.4584, -15.8795]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-21.6690, -17.8718, -22.8979,  ..., -18.6836, -16.1767, -16.3267],\n",
      "        [-16.1311, -14.8238, -15.8236,  ..., -21.2391, -22.0830, -17.2762],\n",
      "        [-14.4758, -18.3518, -18.5808,  ..., -14.1029, -14.0486, -15.7765],\n",
      "        ...,\n",
      "        [-12.4368,  -9.4283, -12.7782,  ...,  -8.4806,  -9.4072, -13.4162],\n",
      "        [-17.4665, -20.4575, -19.8441,  ..., -15.7227, -15.4464, -15.4264],\n",
      "        [-19.0620, -13.9792, -18.5398,  ..., -16.6351, -13.0534, -11.1637]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n",
      "tensor([[-12.6783, -18.8564, -18.8295,  ..., -17.1269, -16.5873, -19.8157],\n",
      "        [-21.9129, -20.7105, -21.0593,  ..., -17.2814, -18.1770, -16.4624],\n",
      "        [-10.9179, -12.1189, -14.2380,  ..., -14.9978, -16.0999, -11.4661],\n",
      "        ...,\n",
      "        [-17.2110, -17.2394, -19.1298,  ..., -12.3348, -13.4980, -13.4908],\n",
      "        [-13.9330, -17.2121, -19.9374,  ..., -20.0996, -18.4519, -16.6538],\n",
      "        [-14.4780, -15.4234, -18.4674,  ..., -19.6057, -20.7663, -18.5485]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "torch.Size([60, 1000])\n",
      "torch.Size([60, 1000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m save_dir_z \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(save_dir, i, idx)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkedmi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m dist_inversion(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     G,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     D,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     targetnets,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     E,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     iden,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     lr\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     iter_times\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39miters_mi\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     momentum\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     lamda\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     clip_range\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     improved\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimproved_flag\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     num_seeds\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mnum_seeds\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     used_loss\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     prefix\u001b[39m=\u001b[39;49msave_dir_z,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     save_img_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_img_dir, \u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(idx)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     fea_mean\u001b[39m=\u001b[39;49mfea_mean,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     fea_logvar\u001b[39m=\u001b[39;49mfea_logvar,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     lam\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m\"\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlam\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     clipz\u001b[39m=\u001b[39;49mconfiguration[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mclipz\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/KEDMI_CELEBA.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m iden \u001b[39m=\u001b[39m iden \u001b[39m+\u001b[39m bs\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/kedmi/utils/kedmi_attack.py:179\u001b[0m, in \u001b[0;36mdist_inversion\u001b[0;34m(G, D, T, E, iden, lr, momentum, lamda, iter_times, clip_range, improved, num_seeds, used_loss, prefix, random_seed, save_img_dir, fea_mean, fea_logvar, lam, clipz)\u001b[0m\n\u001b[1;32m    175\u001b[0m     Prior_Loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m label\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    177\u001b[0m Total_Loss \u001b[39m=\u001b[39m Prior_Loss \u001b[39m+\u001b[39m lamda \u001b[39m*\u001b[39m Iden_Loss\n\u001b[0;32m--> 179\u001b[0m Total_Loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    180\u001b[0m solver\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    182\u001b[0m Prior_Loss_val \u001b[39m=\u001b[39m Prior_Loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin attacking\n",
    "for i in range(1):\n",
    "    iden = torch.from_numpy(np.arange(bs))\n",
    "\n",
    "    # evaluate on the first 300 identities only\n",
    "    target_cosines = 0\n",
    "    eval_cosines = 0\n",
    "    for idx in range(5):\n",
    "        iden = iden % n_classes\n",
    "        print(\n",
    "            \"--------------------- Attack batch [%s]------------------------------\"\n",
    "            % idx\n",
    "        )\n",
    "        print(\"Iden:{}\".format(iden))\n",
    "        save_dir_z = \"{}/{}_{}\".format(save_dir, i, idx)\n",
    "        print(\"kedmi\")\n",
    "\n",
    "        dist_inversion(\n",
    "            G,\n",
    "            D,\n",
    "            targetnets,\n",
    "            E,\n",
    "            iden,\n",
    "            lr=configuration[\"attack\"][\"lr\"],\n",
    "            iter_times=configuration[\"attack\"][\"iters_mi\"],\n",
    "            momentum=0.9,\n",
    "            lamda=100,\n",
    "            clip_range=1,\n",
    "            improved=configuration['attack']['improved_flag'],\n",
    "            num_seeds=configuration['attack']['num_seeds'],\n",
    "            used_loss=configuration['attack']['loss'],\n",
    "            prefix=save_dir_z,\n",
    "            save_img_dir=os.path.join(save_img_dir, \"{}_\".format(idx)),\n",
    "            fea_mean=fea_mean,\n",
    "            fea_logvar=fea_logvar,\n",
    "            lam=configuration[\"attack\"][\"lam\"],\n",
    "            clipz=configuration['attack']['clipz'],\n",
    "        )\n",
    "        iden = iden + bs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
