{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.generator import *\n",
    "from models.discri import *\n",
    "from utils.helper import *\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.kedmi_attack import inversion, dist_inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specified configuration and specify environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"config/celeba/attacking/mnist_cust.json\"\n",
    "configuration = load_json(json_file=CONFIG_PATH)\n",
    "\n",
    "save_folder = os.path.join(\n",
    "    f\"{configuration['dataset']['name']}_{configuration['dataset']['model_name']}\",\n",
    "    configuration[\"attack\"][\"variant\"],\n",
    ")\n",
    "prefix = os.path.join(\n",
    "    os.path.join(configuration[\"root_path\"], \"kedmi_300ids\"), save_folder\n",
    ")\n",
    "save_dir = os.path.join(prefix, \"latent\")\n",
    "save_img_dir = os.path.join(\n",
    "    prefix, \"imgs_{}\".format(configuration[\"attack\"][\"variant\"])\n",
    ")\n",
    "\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VGG16', 'VGG16']\n",
      "path_G ../training/data/model_data/gan/mnist/VGG16/improved_mnist_G.tar\n",
      "path_D ../training/data/model_data/gan/mnist/VGG16/improved_mnist_D.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/coding/bachelorarbeit/ba_code/kedmi/models/discri.py:55: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.T, 0, 1)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../training/data/model_data/gan/mnist/VGG16/improved_mnist_G.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bot/coding/bachelorarbeit/ba_code/kedmi/run_attack_MNIST.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bot/coding/bachelorarbeit/ba_code/kedmi/run_attack_MNIST.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m targetnets, E, G, D, n_classes, fea_mean, fea_logvar \u001b[39m=\u001b[39m get_attack_model(configuration)\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/kedmi/utils/helper.py:238\u001b[0m, in \u001b[0;36mget_attack_model\u001b[0;34m(args_json, eval_mode)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mprint\u001b[39m(model_types_)\n\u001b[1;32m    236\u001b[0m checkpoints \u001b[39m=\u001b[39m args_json[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcls_ckpts\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m G, D \u001b[39m=\u001b[39m get_GAN(args_json[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m],gan_type\u001b[39m=\u001b[39;49margs_json[\u001b[39m'\u001b[39;49m\u001b[39mattack\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimproved_flag\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    239\u001b[0m                 gan_model_dir\u001b[39m=\u001b[39;49margs_json[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mgan_model_dir\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    240\u001b[0m                 n_classes\u001b[39m=\u001b[39;49mn_classes,z_dim\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,target_model\u001b[39m=\u001b[39;49mmodel_types_[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    242\u001b[0m dataset \u001b[39m=\u001b[39m args_json[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    243\u001b[0m cid \u001b[39m=\u001b[39m args_json[\u001b[39m'\u001b[39m\u001b[39mattack\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mclassid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/kedmi/utils/helper.py:223\u001b[0m, in \u001b[0;36mget_GAN\u001b[0;34m(dataset, gan_type, gan_model_dir, n_classes, z_dim, target_model)\u001b[0m\n\u001b[1;32m    221\u001b[0m G \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mDataParallel(G)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    222\u001b[0m D \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mDataParallel(D)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 223\u001b[0m ckp_G \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(path_G)\n\u001b[1;32m    224\u001b[0m G\u001b[39m.\u001b[39mload_state_dict(ckp_G[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m], strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    225\u001b[0m ckp_D \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(path_D)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../training/data/model_data/gan/mnist/VGG16/improved_mnist_G.tar'"
     ]
    }
   ],
   "source": [
    "targetnets, E, G, D, n_classes, fea_mean, fea_logvar = get_attack_model(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set necessary params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "bs = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Attack batch [0]------------------------------\n",
      "Iden:tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "kedmi\n",
      "criterion:logit_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/anaconda3/envs/torch-gpu/lib/python3.10/site-packages/torch/nn/parallel/comm.py:231: UserWarning: Using -1 to represent CPU tensor is deprecated. Please use a device object or string instead, e.g., \"cpu\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:300\tPrior Loss:5.95\tIden Loss:-9.42\tAttack Acc:11.67\n",
      "Iteration:600\tPrior Loss:5.19\tIden Loss:-15.26\tAttack Acc:25.00\n",
      "Iteration:900\tPrior Loss:5.51\tIden Loss:-18.81\tAttack Acc:43.33\n",
      "Iteration:1200\tPrior Loss:5.70\tIden Loss:-20.78\tAttack Acc:50.00\n",
      "Iteration:1500\tPrior Loss:5.60\tIden Loss:-22.01\tAttack Acc:50.00\n",
      "Iteration:1800\tPrior Loss:5.46\tIden Loss:-22.44\tAttack Acc:50.00\n",
      "Iteration:2100\tPrior Loss:5.38\tIden Loss:-22.75\tAttack Acc:48.33\n",
      "Iteration:2400\tPrior Loss:5.38\tIden Loss:-22.88\tAttack Acc:48.33\n",
      "--------------------- Attack batch [1]------------------------------\n",
      "Iden:tensor([ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
      "         74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
      "         88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "        102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "        116, 117, 118, 119])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "Iteration:300\tPrior Loss:5.31\tIden Loss:-9.69\tAttack Acc:10.00\n",
      "Iteration:600\tPrior Loss:4.78\tIden Loss:-16.07\tAttack Acc:26.67\n",
      "Iteration:900\tPrior Loss:5.13\tIden Loss:-19.16\tAttack Acc:43.33\n",
      "Iteration:1200\tPrior Loss:5.20\tIden Loss:-21.00\tAttack Acc:50.00\n",
      "Iteration:1500\tPrior Loss:5.12\tIden Loss:-22.24\tAttack Acc:43.33\n",
      "Iteration:1800\tPrior Loss:5.07\tIden Loss:-22.74\tAttack Acc:51.67\n",
      "Iteration:2100\tPrior Loss:5.16\tIden Loss:-23.00\tAttack Acc:45.00\n",
      "Iteration:2400\tPrior Loss:5.06\tIden Loss:-23.15\tAttack Acc:41.67\n",
      "--------------------- Attack batch [2]------------------------------\n",
      "Iden:tensor([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "        134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
      "        148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
      "        162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
      "        176, 177, 178, 179])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "Iteration:300\tPrior Loss:5.59\tIden Loss:-10.27\tAttack Acc:13.33\n",
      "Iteration:600\tPrior Loss:5.17\tIden Loss:-14.69\tAttack Acc:31.67\n",
      "Iteration:900\tPrior Loss:5.57\tIden Loss:-18.42\tAttack Acc:50.00\n",
      "Iteration:1200\tPrior Loss:5.61\tIden Loss:-20.46\tAttack Acc:48.33\n",
      "Iteration:1500\tPrior Loss:5.69\tIden Loss:-21.66\tAttack Acc:50.00\n",
      "Iteration:1800\tPrior Loss:5.75\tIden Loss:-22.21\tAttack Acc:50.00\n",
      "Iteration:2100\tPrior Loss:5.78\tIden Loss:-22.56\tAttack Acc:48.33\n",
      "Iteration:2400\tPrior Loss:5.70\tIden Loss:-22.72\tAttack Acc:50.00\n",
      "--------------------- Attack batch [3]------------------------------\n",
      "Iden:tensor([180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
      "        194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "        236, 237, 238, 239])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "Iteration:300\tPrior Loss:5.48\tIden Loss:-9.43\tAttack Acc:5.00\n",
      "Iteration:600\tPrior Loss:5.28\tIden Loss:-14.82\tAttack Acc:21.67\n",
      "Iteration:900\tPrior Loss:5.67\tIden Loss:-18.28\tAttack Acc:40.00\n",
      "Iteration:1200\tPrior Loss:5.59\tIden Loss:-20.30\tAttack Acc:45.00\n",
      "Iteration:1500\tPrior Loss:5.71\tIden Loss:-21.41\tAttack Acc:45.00\n",
      "Iteration:1800\tPrior Loss:5.68\tIden Loss:-21.77\tAttack Acc:55.00\n",
      "Iteration:2100\tPrior Loss:5.65\tIden Loss:-22.10\tAttack Acc:50.00\n",
      "Iteration:2400\tPrior Loss:5.68\tIden Loss:-22.27\tAttack Acc:45.00\n",
      "--------------------- Attack batch [4]------------------------------\n",
      "Iden:tensor([240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
      "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
      "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
      "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
      "        296, 297, 298, 299])\n",
      "kedmi\n",
      "criterion:logit_loss\n",
      "Iteration:300\tPrior Loss:5.60\tIden Loss:-9.42\tAttack Acc:10.00\n",
      "Iteration:600\tPrior Loss:5.56\tIden Loss:-15.44\tAttack Acc:23.33\n",
      "Iteration:900\tPrior Loss:5.46\tIden Loss:-18.82\tAttack Acc:31.67\n",
      "Iteration:1200\tPrior Loss:5.65\tIden Loss:-20.98\tAttack Acc:43.33\n",
      "Iteration:1500\tPrior Loss:5.54\tIden Loss:-22.06\tAttack Acc:45.00\n",
      "Iteration:1800\tPrior Loss:5.59\tIden Loss:-22.61\tAttack Acc:48.33\n",
      "Iteration:2100\tPrior Loss:5.56\tIden Loss:-22.81\tAttack Acc:43.33\n",
      "Iteration:2400\tPrior Loss:5.53\tIden Loss:-22.98\tAttack Acc:45.00\n"
     ]
    }
   ],
   "source": [
    "# Begin attacking\n",
    "for i in range(1):\n",
    "    iden = torch.from_numpy(np.arange(bs))\n",
    "\n",
    "    # evaluate on the first 300 identities only\n",
    "    target_cosines = 0\n",
    "    eval_cosines = 0\n",
    "    for idx in range(5):\n",
    "        iden = iden % n_classes\n",
    "        print(\n",
    "            \"--------------------- Attack batch [%s]------------------------------\"\n",
    "            % idx\n",
    "        )\n",
    "        print(\"Iden:{}\".format(iden))\n",
    "        save_dir_z = \"{}/{}_{}\".format(save_dir, i, idx)\n",
    "        print(\"kedmi\")\n",
    "\n",
    "        dist_inversion(\n",
    "            G,\n",
    "            D,\n",
    "            targetnets,\n",
    "            E,\n",
    "            iden,\n",
    "            lr=configuration[\"attack\"][\"lr\"],\n",
    "            iter_times=configuration[\"attack\"][\"iters_mi\"],\n",
    "            momentum=0.9,\n",
    "            lamda=100,\n",
    "            clip_range=1,\n",
    "            improved=configuration['attack']['improved_flag'],\n",
    "            num_seeds=configuration['attack']['num_seeds'],\n",
    "            used_loss=configuration['attack']['loss'],\n",
    "            prefix=save_dir_z,\n",
    "            save_img_dir=os.path.join(save_img_dir, \"{}_\".format(idx)),\n",
    "            fea_mean=fea_mean,\n",
    "            fea_logvar=fea_logvar,\n",
    "            lam=configuration[\"attack\"][\"lam\"],\n",
    "            clipz=configuration['attack']['clipz'],\n",
    "        )\n",
    "        iden = iden + bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
