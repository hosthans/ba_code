{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from directory\n",
      "Training-Process started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 \t Time:106.8654043674469 \t Generator loss: 305.1907043457031\n",
      "Epoch:1 \t Time:105.90501594543457 \t Generator loss: 413.370361328125\n",
      "Epoch:2 \t Time:106.14900779724121 \t Generator loss: 569.7741088867188\n",
      "Epoch:3 \t Time:105.95573949813843 \t Generator loss: 605.4253540039062\n",
      "Epoch:4 \t Time:106.18840861320496 \t Generator loss: 610.325439453125\n",
      "Epoch:5 \t Time:105.91563200950623 \t Generator loss: 631.4796142578125\n",
      "Epoch:6 \t Time:106.06002593040466 \t Generator loss: 591.0032348632812\n",
      "Epoch:7 \t Time:106.0881667137146 \t Generator loss: 683.5508422851562\n",
      "Epoch:8 \t Time:106.05633807182312 \t Generator loss: 657.8782958984375\n",
      "Epoch:9 \t Time:106.14316654205322 \t Generator loss: 655.4195556640625\n",
      "Epoch:10 \t Time:105.9306046962738 \t Generator loss: 622.8055419921875\n",
      "Epoch:11 \t Time:106.05960655212402 \t Generator loss: 653.5701293945312\n",
      "Epoch:12 \t Time:106.08381581306458 \t Generator loss: 671.848876953125\n",
      "Epoch:13 \t Time:106.05953335762024 \t Generator loss: 616.71337890625\n",
      "Epoch:14 \t Time:106.07319903373718 \t Generator loss: 667.794921875\n",
      "Epoch:15 \t Time:106.027188539505 \t Generator loss: 638.8679809570312\n",
      "Epoch:16 \t Time:105.9894347190857 \t Generator loss: 691.1785888671875\n",
      "Epoch:17 \t Time:106.17394089698792 \t Generator loss: 688.7137451171875\n",
      "Epoch:18 \t Time:106.05565881729126 \t Generator loss: 644.763916015625\n",
      "Epoch:19 \t Time:106.13945436477661 \t Generator loss: 663.4351806640625\n",
      "Epoch:20 \t Time:105.97447490692139 \t Generator loss: 683.5830078125\n",
      "Epoch:21 \t Time:105.93889331817627 \t Generator loss: 656.0616455078125\n",
      "Epoch:22 \t Time:106.17992424964905 \t Generator loss: 635.8739013671875\n",
      "Epoch:23 \t Time:106.0113742351532 \t Generator loss: 697.2571411132812\n",
      "Epoch:24 \t Time:106.13305640220642 \t Generator loss: 655.1626586914062\n",
      "Epoch:25 \t Time:106.03331732749939 \t Generator loss: 717.5528564453125\n",
      "Epoch:26 \t Time:105.98907256126404 \t Generator loss: 687.0512084960938\n",
      "Epoch:27 \t Time:107.2335832118988 \t Generator loss: 697.41064453125\n",
      "Epoch:28 \t Time:106.07693409919739 \t Generator loss: 687.64892578125\n",
      "Epoch:29 \t Time:106.09814357757568 \t Generator loss: 698.0604248046875\n",
      "Epoch:30 \t Time:106.15399265289307 \t Generator loss: 725.899658203125\n",
      "Epoch:31 \t Time:106.01537561416626 \t Generator loss: 711.9554443359375\n",
      "Epoch:32 \t Time:106.02257966995239 \t Generator loss: 642.7400512695312\n",
      "Epoch:33 \t Time:106.18197965621948 \t Generator loss: 687.5400390625\n",
      "Epoch:34 \t Time:105.97946095466614 \t Generator loss: 682.0536499023438\n",
      "Epoch:35 \t Time:106.19104623794556 \t Generator loss: 704.104736328125\n",
      "Epoch:36 \t Time:106.02938270568848 \t Generator loss: 687.3642578125\n",
      "Epoch:37 \t Time:105.9896674156189 \t Generator loss: 676.2813720703125\n",
      "Epoch:38 \t Time:106.13903450965881 \t Generator loss: 701.8374633789062\n",
      "Epoch:39 \t Time:106.02322149276733 \t Generator loss: 668.950927734375\n",
      "Epoch:40 \t Time:106.12738728523254 \t Generator loss: 689.193359375\n",
      "Epoch:41 \t Time:106.02134966850281 \t Generator loss: 685.517578125\n",
      "Epoch:42 \t Time:106.01137614250183 \t Generator loss: 711.126708984375\n",
      "Epoch:43 \t Time:106.07305359840393 \t Generator loss: 709.6131591796875\n",
      "Epoch:44 \t Time:106.06722640991211 \t Generator loss: 700.902099609375\n",
      "Epoch:45 \t Time:106.38382911682129 \t Generator loss: 717.3731689453125\n",
      "Epoch:46 \t Time:106.10911464691162 \t Generator loss: 688.811767578125\n",
      "Epoch:47 \t Time:106.02369356155396 \t Generator loss: 720.0606079101562\n",
      "Epoch:48 \t Time:106.02141451835632 \t Generator loss: 695.795654296875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanwe\\ba_code\\test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hanwe/ba_code/test.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\u001b[39m\"\u001b[39;49m\u001b[39mgan\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfmnist\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\ba_code\\utils\\trainer.py:80\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model_type, dataset, mode)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_dis \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m], betas\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m, \u001b[39m0.999\u001b[39m))\n\u001b[0;32m     79\u001b[0m     \u001b[39m# trigger training\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_gan()\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mtraining method not implemented yet\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\ba_code\\utils\\trainer.py:162\u001b[0m, in \u001b[0;36mTrainer.train_gan\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m f_logit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator(f_imgs)\n\u001b[0;32m    161\u001b[0m wd \u001b[39m=\u001b[39m r_logit\u001b[39m.\u001b[39mmean() \u001b[39m-\u001b[39m f_logit\u001b[39m.\u001b[39mmean() \u001b[39m# Wasserstein-1 Distance\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m gp \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mgradient_penalty(imgs\u001b[39m.\u001b[39;49mdata, f_imgs\u001b[39m.\u001b[39;49mdata, DG\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiscriminator)\n\u001b[0;32m    163\u001b[0m dg_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m wd \u001b[39m+\u001b[39m gp \u001b[39m*\u001b[39m \u001b[39m10.0\u001b[39m\n\u001b[0;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_dis\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\ba_code\\utils\\helper.py:66\u001b[0m, in \u001b[0;36mgradient_penalty\u001b[1;34m(x, y, DG)\u001b[0m\n\u001b[0;32m     63\u001b[0m z \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     64\u001b[0m z\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m o \u001b[39m=\u001b[39m DG(z)\n\u001b[0;32m     67\u001b[0m g \u001b[39m=\u001b[39m grad(o, z, grad_outputs\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mones(o\u001b[39m.\u001b[39msize())\u001b[39m.\u001b[39mcuda(), create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(z\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     68\u001b[0m gp \u001b[39m=\u001b[39m ((g\u001b[39m.\u001b[39mnorm(p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:161\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj:\n\u001b[0;32m    157\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule must have its parameters and buffers \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mon device \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (device_ids[0]) but found one of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mthem on device: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj, t\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m--> 161\u001b[0m inputs, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscatter(inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids)\n\u001b[0;32m    162\u001b[0m \u001b[39m# for forward function without any inputs, empty list and dict will be created\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m# so the module can be executed on one device which is the first one in device_ids\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inputs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.scatter\u001b[1;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\u001b[39mself\u001b[39m, inputs, kwargs, device_ids):\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_kwargs(inputs, kwargs, device_ids, dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim)\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py:52\u001b[0m, in \u001b[0;36mscatter_kwargs\u001b[1;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_kwargs\u001b[39m(inputs, kwargs, target_gpus, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m     51\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     inputs \u001b[39m=\u001b[39m scatter(inputs, target_gpus, dim) \u001b[39mif\u001b[39;00m inputs \u001b[39melse\u001b[39;00m []\n\u001b[0;32m     53\u001b[0m     kwargs \u001b[39m=\u001b[39m scatter(kwargs, target_gpus, dim) \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m []\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(kwargs):\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py:44\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# After scatter_map is called, a scatter_map cell will exist. This cell\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m# has a reference to the actual function scatter_map, which has references\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# to a closure that has a reference to the scatter_map cell (because the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# fn is recursive). To avoid this reference cycle, we set the function to\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m# None, clearing the cell\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     res \u001b[39m=\u001b[39m scatter_map(inputs)\n\u001b[0;32m     45\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     scatter_map \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py:31\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mtype\u001b[39m(obj)(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(scatter_map, obj)))\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mlist\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\scatter_gather.py:27\u001b[0m, in \u001b[0;36mscatter.<locals>.scatter_map\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_map\u001b[39m(obj):\n\u001b[0;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m Scatter\u001b[39m.\u001b[39;49mapply(target_gpus, \u001b[39mNone\u001b[39;49;00m, dim, obj)\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m _is_namedtuple(obj):\n\u001b[0;32m     29\u001b[0m         \u001b[39mreturn\u001b[39;00m [\u001b[39mtype\u001b[39m(obj)(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(scatter_map, obj))]\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\autograd\\function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mapply(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[0;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:96\u001b[0m, in \u001b[0;36mScatter.forward\u001b[1;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39mand\u001b[39;00m ctx\u001b[39m.\u001b[39minput_device \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m     94\u001b[0m     \u001b[39m# Perform CPU to GPU copies in a background stream\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     streams \u001b[39m=\u001b[39m [_get_stream(device) \u001b[39mfor\u001b[39;00m device \u001b[39min\u001b[39;00m target_gpus]\n\u001b[1;32m---> 96\u001b[0m outputs \u001b[39m=\u001b[39m comm\u001b[39m.\u001b[39;49mscatter(\u001b[39minput\u001b[39;49m, target_gpus, chunk_sizes, ctx\u001b[39m.\u001b[39;49mdim, streams)\n\u001b[0;32m     97\u001b[0m \u001b[39m# Synchronize with the copy stream\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m streams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hanwe\\.conda\\envs\\gpu\\lib\\site-packages\\torch\\nn\\parallel\\comm.py:189\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     devices \u001b[39m=\u001b[39m [_get_device_index(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m devices]\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_scatter(tensor, devices, chunk_sizes, dim, streams))\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m devices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\"gan\", \"fmnist\", \"gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
