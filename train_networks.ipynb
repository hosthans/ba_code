{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 21:41:18.685845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from training.utils.trainer import Trainer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dataset=\"mnist\", mode=\"nn\")\n",
    "loss_nn, acc_nn, loss_t_nn, acc_t_nn = trainer.train()\n",
    "\n",
    "with open(\"training_metrics/nn_training_data.pkl\", 'wb') as file:\n",
    "    data_to_save = {\n",
    "        'loss_train': loss_nn, \n",
    "        'loss_test': loss_t_nn,\n",
    "        'acc_train': acc_nn,\n",
    "        'acc_test': acc_t_nn\n",
    "    }\n",
    "    pickle.dump(data_to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train celebA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'celeba', 'indices': False, 'gray': False, 'train_file': 'datasets/meta_celeba/trainset.txt', 'test_file': 'datasets/meta_celeba/testset.txt', 'gan_file': 'datasets/meta_celeba/ganset.txt', 'img_path': 'datasets/celeba/img_align_celeba', 'img_gan_path': 'datasets/celeba/img_align_celeba', 'model_name': 'VGG16_celeba', 'num_classes': 1000}\n",
      "----------------Loading datasets-----------------\n",
      "Load 27018 images\n",
      "Load 3009 images\n",
      "<training.utils.dataloader.ImageFolder object at 0x7fc6f06f0910>\n",
      "---------------Loading dataloader----------------\n",
      "DataLoader initialized\n",
      "DataLoader initialized\n",
      "Draw Graph in Tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bot/.local/lib/python3.10/site-packages/torch/jit/_trace.py:1065: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  module._c._create_method_from_trace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Process started!\n",
      "Epoch:0\tTime:72.17\tTrain Loss:7.04\tTrain Acc:0.14\tTest Acc0.14\n",
      "Epoch:1\tTime:71.14\tTrain Loss:6.86\tTrain Acc:0.34\tTest Acc0.36\n",
      "Epoch:2\tTime:71.43\tTrain Loss:6.69\tTrain Acc:1.14\tTest Acc0.96\n",
      "Epoch:3\tTime:71.78\tTrain Loss:6.50\tTrain Acc:2.63\tTest Acc2.10\n",
      "Epoch:4\tTime:37.94\tTrain Loss:6.31\tTrain Acc:5.19\tTest Acc3.41\n",
      "Epoch:5\tTime:34.45\tTrain Loss:6.12\tTrain Acc:7.75\tTest Acc5.26\n",
      "Epoch:6\tTime:34.47\tTrain Loss:5.92\tTrain Acc:10.83\tTest Acc7.24\n",
      "Epoch:7\tTime:34.63\tTrain Loss:5.71\tTrain Acc:13.71\tTest Acc8.70\n",
      "Epoch:8\tTime:34.61\tTrain Loss:5.51\tTrain Acc:16.83\tTest Acc10.69\n",
      "Epoch:9\tTime:34.64\tTrain Loss:5.32\tTrain Acc:19.93\tTest Acc12.54\n",
      "Epoch:10\tTime:34.98\tTrain Loss:5.13\tTrain Acc:22.78\tTest Acc14.63\n",
      "Epoch:11\tTime:34.76\tTrain Loss:4.94\tTrain Acc:25.98\tTest Acc16.26\n",
      "Epoch:12\tTime:34.63\tTrain Loss:4.76\tTrain Acc:29.06\tTest Acc18.36\n",
      "Epoch:13\tTime:34.45\tTrain Loss:4.60\tTrain Acc:31.86\tTest Acc20.24\n",
      "Epoch:14\tTime:34.75\tTrain Loss:4.43\tTrain Acc:34.74\tTest Acc22.02\n",
      "Epoch:15\tTime:34.79\tTrain Loss:4.27\tTrain Acc:37.71\tTest Acc23.47\n",
      "Epoch:16\tTime:34.72\tTrain Loss:4.11\tTrain Acc:40.90\tTest Acc24.96\n",
      "Epoch:17\tTime:34.90\tTrain Loss:3.96\tTrain Acc:43.14\tTest Acc26.49\n",
      "Epoch:18\tTime:34.35\tTrain Loss:3.81\tTrain Acc:45.78\tTest Acc28.37\n",
      "Epoch:19\tTime:34.57\tTrain Loss:3.67\tTrain Acc:48.44\tTest Acc30.40\n",
      "Epoch:20\tTime:34.51\tTrain Loss:3.53\tTrain Acc:50.84\tTest Acc31.36\n",
      "Epoch:21\tTime:34.28\tTrain Loss:3.39\tTrain Acc:52.82\tTest Acc33.35\n",
      "Epoch:22\tTime:34.58\tTrain Loss:3.27\tTrain Acc:55.42\tTest Acc35.48\n",
      "Epoch:23\tTime:34.68\tTrain Loss:3.14\tTrain Acc:57.40\tTest Acc37.14\n",
      "Epoch:24\tTime:34.50\tTrain Loss:3.02\tTrain Acc:59.55\tTest Acc38.42\n",
      "Epoch:25\tTime:34.99\tTrain Loss:2.90\tTrain Acc:61.28\tTest Acc39.95\n",
      "Epoch:26\tTime:34.44\tTrain Loss:2.79\tTrain Acc:63.45\tTest Acc41.30\n",
      "Epoch:27\tTime:34.90\tTrain Loss:2.68\tTrain Acc:65.24\tTest Acc42.72\n",
      "Epoch:28\tTime:34.52\tTrain Loss:2.57\tTrain Acc:67.03\tTest Acc43.36\n",
      "Epoch:29\tTime:34.48\tTrain Loss:2.46\tTrain Acc:69.02\tTest Acc44.67\n",
      "Epoch:30\tTime:34.49\tTrain Loss:2.37\tTrain Acc:70.69\tTest Acc45.81\n",
      "Epoch:31\tTime:34.96\tTrain Loss:2.27\tTrain Acc:71.94\tTest Acc47.59\n",
      "Epoch:32\tTime:34.32\tTrain Loss:2.18\tTrain Acc:73.71\tTest Acc47.87\n",
      "Epoch:33\tTime:34.83\tTrain Loss:2.09\tTrain Acc:75.03\tTest Acc49.25\n",
      "Epoch:34\tTime:34.54\tTrain Loss:2.00\tTrain Acc:76.58\tTest Acc50.50\n",
      "Epoch:35\tTime:34.37\tTrain Loss:1.93\tTrain Acc:77.83\tTest Acc51.17\n",
      "Epoch:36\tTime:34.40\tTrain Loss:1.84\tTrain Acc:79.08\tTest Acc51.53\n",
      "Epoch:37\tTime:34.86\tTrain Loss:1.77\tTrain Acc:80.36\tTest Acc52.27\n",
      "Epoch:38\tTime:34.73\tTrain Loss:1.69\tTrain Acc:81.57\tTest Acc53.48\n",
      "Epoch:39\tTime:35.01\tTrain Loss:1.62\tTrain Acc:82.84\tTest Acc53.59\n",
      "Epoch:40\tTime:34.82\tTrain Loss:1.55\tTrain Acc:83.49\tTest Acc54.40\n",
      "Epoch:41\tTime:34.98\tTrain Loss:1.49\tTrain Acc:84.67\tTest Acc54.83\n",
      "Epoch:42\tTime:34.50\tTrain Loss:1.43\tTrain Acc:85.37\tTest Acc54.87\n",
      "Epoch:43\tTime:34.93\tTrain Loss:1.36\tTrain Acc:86.42\tTest Acc55.43\n",
      "Epoch:44\tTime:34.80\tTrain Loss:1.31\tTrain Acc:87.25\tTest Acc56.04\n",
      "Epoch:45\tTime:34.70\tTrain Loss:1.25\tTrain Acc:88.06\tTest Acc55.93\n",
      "Epoch:46\tTime:41.32\tTrain Loss:1.20\tTrain Acc:88.74\tTest Acc57.00\n",
      "Epoch:47\tTime:43.09\tTrain Loss:1.15\tTrain Acc:89.48\tTest Acc57.00\n",
      "Epoch:48\tTime:35.18\tTrain Loss:1.10\tTrain Acc:90.03\tTest Acc57.39\n",
      "Epoch:49\tTime:34.93\tTrain Loss:1.05\tTrain Acc:90.73\tTest Acc58.84\n",
      "Epoch:50\tTime:34.92\tTrain Loss:1.01\tTrain Acc:91.40\tTest Acc58.74\n",
      "Epoch:51\tTime:34.63\tTrain Loss:0.96\tTrain Acc:91.97\tTest Acc58.98\n",
      "Epoch:52\tTime:34.86\tTrain Loss:0.92\tTrain Acc:92.55\tTest Acc59.98\n",
      "Epoch:53\tTime:34.93\tTrain Loss:0.88\tTrain Acc:93.14\tTest Acc59.87\n",
      "Epoch:54\tTime:34.81\tTrain Loss:0.84\tTrain Acc:93.56\tTest Acc60.40\n",
      "Epoch:55\tTime:34.73\tTrain Loss:0.81\tTrain Acc:94.07\tTest Acc60.51\n",
      "Epoch:56\tTime:35.04\tTrain Loss:0.77\tTrain Acc:94.55\tTest Acc60.83\n",
      "Epoch:57\tTime:35.15\tTrain Loss:0.74\tTrain Acc:94.82\tTest Acc60.76\n",
      "Epoch:58\tTime:34.73\tTrain Loss:0.71\tTrain Acc:95.18\tTest Acc60.83\n",
      "Epoch:59\tTime:34.71\tTrain Loss:0.68\tTrain Acc:95.53\tTest Acc60.51\n",
      "Epoch:60\tTime:35.11\tTrain Loss:0.65\tTrain Acc:96.04\tTest Acc61.79\n",
      "Epoch:61\tTime:35.00\tTrain Loss:0.62\tTrain Acc:96.29\tTest Acc61.93\n",
      "Epoch:62\tTime:34.82\tTrain Loss:0.59\tTrain Acc:96.53\tTest Acc61.97\n",
      "Epoch:63\tTime:35.08\tTrain Loss:0.57\tTrain Acc:96.77\tTest Acc62.07\n",
      "Epoch:64\tTime:35.04\tTrain Loss:0.55\tTrain Acc:97.05\tTest Acc62.00\n",
      "Epoch:65\tTime:34.42\tTrain Loss:0.52\tTrain Acc:97.38\tTest Acc62.36\n",
      "Epoch:66\tTime:34.58\tTrain Loss:0.50\tTrain Acc:97.53\tTest Acc62.64\n",
      "Epoch:67\tTime:34.81\tTrain Loss:0.48\tTrain Acc:97.81\tTest Acc62.54\n",
      "Epoch:68\tTime:34.51\tTrain Loss:0.46\tTrain Acc:97.98\tTest Acc62.93\n",
      "Epoch:69\tTime:35.15\tTrain Loss:0.44\tTrain Acc:98.06\tTest Acc63.25\n",
      "Epoch:70\tTime:34.82\tTrain Loss:0.43\tTrain Acc:98.26\tTest Acc63.60\n",
      "Epoch:71\tTime:34.80\tTrain Loss:0.40\tTrain Acc:98.48\tTest Acc63.67\n",
      "Epoch:72\tTime:34.84\tTrain Loss:0.39\tTrain Acc:98.63\tTest Acc63.57\n",
      "Epoch:73\tTime:34.68\tTrain Loss:0.37\tTrain Acc:98.70\tTest Acc63.67\n",
      "Epoch:74\tTime:34.70\tTrain Loss:0.36\tTrain Acc:98.84\tTest Acc63.88\n",
      "Epoch:75\tTime:34.44\tTrain Loss:0.35\tTrain Acc:98.90\tTest Acc63.81\n",
      "Epoch:76\tTime:35.00\tTrain Loss:0.33\tTrain Acc:99.06\tTest Acc63.42\n",
      "Epoch:77\tTime:34.71\tTrain Loss:0.32\tTrain Acc:99.05\tTest Acc64.03\n",
      "Epoch:78\tTime:34.83\tTrain Loss:0.31\tTrain Acc:99.13\tTest Acc64.77\n",
      "Epoch:79\tTime:34.91\tTrain Loss:0.30\tTrain Acc:99.19\tTest Acc64.17\n",
      "Epoch:80\tTime:34.69\tTrain Loss:0.28\tTrain Acc:99.34\tTest Acc64.45\n",
      "Epoch:81\tTime:34.80\tTrain Loss:0.27\tTrain Acc:99.40\tTest Acc64.17\n",
      "Epoch:82\tTime:35.02\tTrain Loss:0.26\tTrain Acc:99.50\tTest Acc64.84\n",
      "Epoch:83\tTime:34.82\tTrain Loss:0.26\tTrain Acc:99.51\tTest Acc64.35\n",
      "Epoch:84\tTime:35.42\tTrain Loss:0.25\tTrain Acc:99.53\tTest Acc64.45\n",
      "Epoch:85\tTime:34.89\tTrain Loss:0.24\tTrain Acc:99.62\tTest Acc65.91\n",
      "Epoch:86\tTime:34.57\tTrain Loss:0.23\tTrain Acc:99.59\tTest Acc64.77\n",
      "Epoch:87\tTime:35.10\tTrain Loss:0.22\tTrain Acc:99.67\tTest Acc64.95\n",
      "Epoch:88\tTime:35.36\tTrain Loss:0.21\tTrain Acc:99.69\tTest Acc65.20\n",
      "Epoch:89\tTime:34.60\tTrain Loss:0.21\tTrain Acc:99.69\tTest Acc64.95\n",
      "Epoch:90\tTime:35.49\tTrain Loss:0.20\tTrain Acc:99.70\tTest Acc65.48\n",
      "Epoch:91\tTime:35.06\tTrain Loss:0.19\tTrain Acc:99.78\tTest Acc65.13\n",
      "Epoch:92\tTime:35.39\tTrain Loss:0.19\tTrain Acc:99.81\tTest Acc65.62\n",
      "Epoch:93\tTime:35.47\tTrain Loss:0.18\tTrain Acc:99.78\tTest Acc65.31\n",
      "Epoch:94\tTime:34.99\tTrain Loss:0.18\tTrain Acc:99.81\tTest Acc65.98\n",
      "Epoch:95\tTime:35.20\tTrain Loss:0.17\tTrain Acc:99.85\tTest Acc65.91\n",
      "Epoch:96\tTime:34.60\tTrain Loss:0.16\tTrain Acc:99.84\tTest Acc65.77\n",
      "Epoch:97\tTime:34.61\tTrain Loss:0.16\tTrain Acc:99.89\tTest Acc65.52\n",
      "Epoch:98\tTime:34.91\tTrain Loss:0.15\tTrain Acc:99.88\tTest Acc65.80\n",
      "Epoch:99\tTime:34.64\tTrain Loss:0.15\tTrain Acc:99.90\tTest Acc65.70\n",
      "Epoch:100\tTime:34.96\tTrain Loss:0.15\tTrain Acc:99.87\tTest Acc65.70\n",
      "Epoch:101\tTime:34.59\tTrain Loss:0.14\tTrain Acc:99.89\tTest Acc65.45\n",
      "Epoch:102\tTime:34.97\tTrain Loss:0.14\tTrain Acc:99.90\tTest Acc65.27\n",
      "Epoch:103\tTime:34.51\tTrain Loss:0.13\tTrain Acc:99.92\tTest Acc65.73\n",
      "Epoch:104\tTime:34.89\tTrain Loss:0.13\tTrain Acc:99.93\tTest Acc65.70\n",
      "Epoch:105\tTime:34.63\tTrain Loss:0.13\tTrain Acc:99.94\tTest Acc65.87\n",
      "Epoch:106\tTime:34.83\tTrain Loss:0.12\tTrain Acc:99.93\tTest Acc65.84\n",
      "Epoch:107\tTime:34.86\tTrain Loss:0.12\tTrain Acc:99.95\tTest Acc65.98\n",
      "Epoch:108\tTime:34.75\tTrain Loss:0.12\tTrain Acc:99.96\tTest Acc65.80\n",
      "Epoch:109\tTime:34.58\tTrain Loss:0.11\tTrain Acc:99.96\tTest Acc65.87\n",
      "Epoch:110\tTime:35.23\tTrain Loss:0.11\tTrain Acc:99.96\tTest Acc66.23\n",
      "Epoch:111\tTime:34.75\tTrain Loss:0.11\tTrain Acc:99.97\tTest Acc66.23\n",
      "Epoch:112\tTime:34.88\tTrain Loss:0.11\tTrain Acc:99.98\tTest Acc66.09\n",
      "Epoch:113\tTime:34.63\tTrain Loss:0.10\tTrain Acc:99.96\tTest Acc66.26\n",
      "Epoch:114\tTime:34.99\tTrain Loss:0.10\tTrain Acc:99.97\tTest Acc65.91\n",
      "Epoch:115\tTime:34.91\tTrain Loss:0.10\tTrain Acc:99.97\tTest Acc66.19\n",
      "Epoch:116\tTime:34.64\tTrain Loss:0.10\tTrain Acc:99.97\tTest Acc66.51\n",
      "Epoch:117\tTime:34.97\tTrain Loss:0.10\tTrain Acc:99.97\tTest Acc65.80\n",
      "Epoch:118\tTime:34.59\tTrain Loss:0.09\tTrain Acc:99.98\tTest Acc65.91\n",
      "Epoch:119\tTime:35.17\tTrain Loss:0.09\tTrain Acc:99.97\tTest Acc66.73\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceleba\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m loss_nn, acc_nn, loss_t_nn, acc_t_nn \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_metrics/nn_training_celeba_data.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m     data_to_save \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_train\u001b[39m\u001b[38;5;124m'\u001b[39m: loss_nn, \n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_test\u001b[39m\u001b[38;5;124m'\u001b[39m: loss_t_nn,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_train\u001b[39m\u001b[38;5;124m'\u001b[39m: acc_nn,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc_test\u001b[39m\u001b[38;5;124m'\u001b[39m: acc_t_nn\n\u001b[1;32m     10\u001b[0m     }\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/training/utils/trainer.py:182\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 182\u001b[0m         loss, acc, loss_t, acc_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc, loss_t, acc_t\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgan\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/coding/bachelorarbeit/ba_code/training/utils/trainer.py:329\u001b[0m, in \u001b[0;36mTrainer.train_nn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    328\u001b[0m out_iden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(out_prob, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m ACC \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43miden\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_iden\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m loss_tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m bs\n\u001b[1;32m    331\u001b[0m cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(dataset=\"celeba\", mode=\"nn\")\n",
    "loss_nn, acc_nn, loss_t_nn, acc_t_nn = trainer.train()\n",
    "\n",
    "with open(\"training_metrics/nn_training_celeba_data.pkl\", 'wb') as file:\n",
    "    data_to_save = {\n",
    "        'loss_train': loss_nn, \n",
    "        'loss_test': loss_t_nn,\n",
    "        'acc_train': acc_nn,\n",
    "        'acc_test': acc_t_nn\n",
    "    }\n",
    "    pickle.dump(data_to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train dp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(dataset=\"mnist\", mode=\"dpnn\")\n",
    "trainer.correct_module()\n",
    "loss, acc, loss_t, acc_t, eps = trainer.train()\n",
    "\n",
    "with open(\"training_metrics/dp_training_data_celeba.pkl\", 'wb') as file:\n",
    "    data_to_save = {\n",
    "        'loss_train': loss, \n",
    "        'loss_test': loss_t,\n",
    "        'acc_train': acc,\n",
    "        'acc_test': acc_t,\n",
    "        'epsilons': eps\n",
    "    }\n",
    "    pickle.dump(data_to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
